---
title: "Coding Assignment 1"
author: "Pierson Wodarz (wodarz2)"
date: "8/29/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
uid = 9679
set.seed(uid)
```

## Data Generation

### Generate Centers
```{r}
p = 2;      
csize = 10;     # number of centers
sigma = 1;      # sd for generating the centers 
m1 = matrix(rnorm(csize*p), csize, p)*sigma + 
  cbind( rep(1, csize), rep(0, csize))
m0 = matrix(rnorm(csize*p), csize, p)*sigma + 
  cbind( rep(0, csize), rep(1, csize))
```

### Generate Data
```{r}
sim_params = list(
 csize = 10,      # number of centers
 p = 2,           # dimension
 s = sqrt(1/5),   # standard deviation for generating data
 n = 200,         # training size per class
 N = 10000,        # test size per class
 m0 = m0,         # 10 centers for class 0
 m1 = m1         # 10 centers for class 1
)
datagen = function(sim_params){
  p = sim_params$p
  s = sim_params$s 
  n = sim_params$n 
  N = sim_params$N 
  m1 = sim_params$m1 
  m0 = sim_params$m0
  csize = sim_params$csize
  
  id1 = sample(1:csize, n, replace = TRUE);
  id0 = sample(1:csize, n, replace = TRUE);
  traindata = matrix(rnorm(2*n*p), 2*n, p)*s + rbind(m1[id1,], m0[id0,])
  Ytrain = factor(c(rep(1,n), rep(0,n)))
  shuffle_row_id = sample(1:n)
  id1 = sample(1:csize, N, replace=TRUE);
  id0 = sample(1:csize, N, replace=TRUE); 
  testdata = matrix(rnorm(2*N*p), 2*N, p)*s + rbind(m1[id1,], m0[id0,])
  Ytest = factor(c(rep(1,N), rep(0,N)))
  
  # Return the training/test data along with labels
  list(
  traindata = traindata,
  Ytrain = Ytrain,
  testdata = testdata,
  Ytest = Ytest
  )
}
```

### Visualize the Data
```{r}
mydata = datagen(sim_params)
traindata = mydata$train
Ytrain = mydata$Ytrain
testdata = mydata$testdata
Ytest = mydata$Ytest
n = nrow(traindata)

mycol = rep("blue", n)
mycol[Ytrain==0] = "red"
plot(traindata[, 1], traindata[, 2], type = "n", xlab = "", ylab = "")
points(traindata[, 1], traindata[, 2], col = mycol);
points(m1[, 1], m1[, 2], pch = "+", cex = 2, col = "blue");    
points(m0[, 1], m0[, 2], pch = "+", cex = 2, col = "red");   
legend("bottomright", pch = c(1,1), col = c("blue", "red"), 
       legend = c("class 1", "class 0"))  
```

## Part I
### KNN implementation
```{r}
scratch_knn = function(traindata, testdata, Ytrain, k){
  if(k > length(traindata)){
    print( "K is larger than number of datapoints")
    return()
  }
  classification = rep(0, nrow(testdata))
  for(i in 1:nrow(testdata)){
    testpoint = testdata[i,]
    class = classify(traindata, testpoint, Ytrain, k)
    classification[i] = class
  }
  as.factor(classification)
}

classify = function(traindata, datapoint, Ytrain, k){
  k_nearest = nearest_neighbors(traindata, datapoint, Ytrain, k)
  if(k==1){
    return(k_nearest[2])
  }
  c = rep(0, length(levels(Ytrain)))
  for(i in 1:k){
    c[k_nearest[i,2]] = c[k_nearest[i,2]] + 1
  }
  which(c==max(c), arr.ind=TRUE)[1]
}

nearest_neighbors = function(traindata, datapoint, Ytrain, k){
  testpoint =  matrix(datapoint, nrow = nrow(traindata), ncol = ncol(traindata), byrow = TRUE)
  distances = (traindata - testpoint)^2
  distances = rowSums(distances)
  distances = sqrt(distances)
  nearest_k_neighbors = cbind(distances, Ytrain)
  nearest_k_neighbors = nearest_k_neighbors[order(nearest_k_neighbors[,1], decreasing = FALSE),]
  nearest_k_neighbors[1:k,]
}

```


K = 1
```{r}
library(class)
test.pred = knn(traindata,testdata,Ytrain,k=1)
table(Ytest, test.pred)
test.scratch_pred = scratch_knn(traindata, testdata,Ytrain,k=1)
table(Ytest, test.scratch_pred)
```

K = 3
```{r}
test.pred = knn(traindata,testdata,Ytrain,k=3)
test.pred_prob = knn(traindata,testdata,Ytrain,k=3,prob=TRUE)
table(Ytest, test.pred)
test.scratch_pred = scratch_knn(traindata, testdata,Ytrain,k=3)
table(Ytest, test.scratch_pred)
```
As we can see above, the tables are not exactly equivalent. This is due to `r length(attributes(test.pred_prob)$prob[attributes(test.pred_prob)$prob == 0.5])` values for which the built-in knn function has a probability of 0.5. As such, we could expect a variation between the built-in knn function and our implementation of knn to have different classifications for up to `r length(attributes(test.pred_prob)$prob[attributes(test.pred_prob)$prob == 0.5])` values, which we see here.
```{r}
length(attributes(test.pred_prob)$prob[attributes(test.pred_prob)$prob == 0.5])
```

K = 5
```{r}
test.pred = knn(traindata,testdata,Ytrain,k=5)
table(Ytest, test.pred)
#length(attributes(test.pred)$prob[attributes(test.pred)$prob == 0.5])
test.scratch_pred = scratch_knn(traindata, testdata,Ytrain,k=5)
table(Ytest, test.scratch_pred)
```

### Handling Ties
Distance Ties: In the code, distances are calculated for all points, and then sorted (see 'nearest_neighbor' function). Then, the first k elements of the matrix are selected. Therefore, distances ties arise when there is a tie on the kth point and some points >= k+1. The tie is resolved by simply taking up to the kth element. In this case, that means that the 'order' function, used for sorting the matrix by distance, is actually determining the order and therefore breaking the ties. From the [documentation](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/order): "The sort used is stable, so any unresolved ties will be left in their original ordering". Therefore, we can see that ties are broken by initial ordering of the input dataset. 

Voting Ties: Voting ties are broken in the 'classify' function. In this case, we create a matrix which calculates the count for each class, and then find the index of the maximum of these counts. A voting tie would arise when there are multiple indices that represent a maximal count (in the case of a tie between different classes). We take the first element of this resulting index array. In practice, this means that the lowest level/classification is used in the case of a voting tie. 

## Part II
### Linear Regression
```{r}
fit_lr_model = function(sim_data){
  # change Y from factor to numeric
  sim_data$Ytrain = as.numeric(sim_data$Ytrain) - 1
  sim_data$Ytest = as.numeric(sim_data$Ytest) - 1
  
  # fit a linear regression model
  model = lm(sim_data$Ytrain ~ ., data=as.data.frame(sim_data$traindata))
  decision_thresh = 0.5
  train_pred = as.numeric(model$fitted.values > decision_thresh)
  
  # Make predictions
  test_yhat = predict(model, newdata=as.data.frame(sim_data$testdata))
  test_pred = as.numeric(test_yhat > decision_thresh)
  
  # return the mean classification errors on training/test sets
  list(
    train_error = sum(sim_data$Ytrain  != train_pred) / length(sim_data$Ytrain),
    test_error = sum(sim_data$Ytest  != test_pred) / 
      length(sim_data$Ytest)
  )
}
```

### Quadratic Regression
```{r}
fit_qr_model = function(sim_data, verbose=FALSE) {
  
  # change Y from factor to numeric
  sim_data$Ytrain = as.numeric(sim_data$Ytrain) - 1
  sim_data$Ytest = as.numeric(sim_data$Ytest) - 1
  
  # fit a quadratic regression model
  model = lm(
    sim_data$Ytrain ~ 
      V1 + V2 + I(V1^2) + I(V2^2) + V1:V2,
    as.data.frame(sim_data$traindata)
  )
  if (verbose) {
    print(summary(model))
  }
  
  decision_thresh = 0.5
  train_pred = as.numeric(model$fitted.values > decision_thresh)
 
  test_yhat = predict(
    model,
    newdata=as.data.frame(sim_data$testdata)
  )
  test_pred = as.numeric(test_yhat > decision_thresh)
  
  # return the mean classification errors on training/test sets
  list(
    train_error = sum(sim_data$Ytrain  != train_pred) / length(sim_data$Ytrain),
    test_error = sum(sim_data$Ytest  != test_pred) / 
      length(sim_data$Ytest)
  )
}
```

### CV-KNN
```{r}
cvKNNAveErrorRate = function(K, train_data, Ytrain, foldNum=10){
  n = nrow(traindata)
  foldSize = floor(n/foldNum)  
  error = 0
  myIndex = sample(1 : n)
  for(runId in 1:foldNum){
    testSetIndex = ((runId-1)*foldSize + 1):(ifelse(runId == foldNum, n, runId*foldSize))
    testSetIndex = myIndex[testSetIndex]
    trainX = traindata[-testSetIndex, ]
    trainY = Ytrain[-testSetIndex]
    testX = traindata[testSetIndex, ]
    testY = Ytrain[testSetIndex]
    predictY = knn(trainX, testX, trainY, K)
    error = error + sum(predictY != testY) 
  }
  error = error / n
  error
}
```

```{r}
cvKNN = function(traindata, Ytrain, foldNum=10) {
  n = nrow(traindata)
  foldSize = floor(n/foldNum)  
  #KVector = seq(1, (nrow(traindata) - foldSize), 1)
  KVector = cbind(1, 3, 5)
  cvErrorRates = sapply(KVector, cvKNNAveErrorRate, traindata, Ytrain, foldNum)
  result = list()
  result$bestK = max(KVector[cvErrorRates == min(cvErrorRates)])
  result$cvError = cvErrorRates[KVector == result$bestK]
  result
}
```

```{r}
fit_knn_model = function(sim_data, k){
  train_pred = knn(sim_data$train, sim_data$train, sim_data$Ytrain, k)
  test_pred = knn(sim_data$train, sim_data$testdata, sim_data$Ytrain, k)
  
  # return the mean classification errors on training/test sets
  list(
    train_error = sum(sim_data$Ytrain  != train_pred) / length(sim_data$Ytrain),
    test_error = sum(sim_data$Ytest  != test_pred) / 
      length(sim_data$Ytest)
  )
}
```


### Bayes Rule
```{r}
mixnorm = function(x, centers0, centers1, s){
  ## return the density ratio for a point x, where each 
  ## density is a mixture of normal with multiple components
  d1 = sum(exp(-apply((t(centers1) - x)^2, 2, sum) / (2 * s^2)))
  d0 = sum(exp(-apply((t(centers0) - x)^2, 2, sum) / (2 * s^2)))
  
  return (d1 / d0)
}
```

```{r}
fit_bayes_model = function(sim_data, centers0, centers1, s){
  sim_data$Ytrain = as.numeric(sim_data$Ytrain) - 1
  sim_data$Ytest = as.numeric(sim_data$Ytest) - 1
  decision_thresh = 1
  train_pred = rep(0, length(sim_data$Ytrain))
  test_pred = rep(0, length(sim_data$Ytest))
  for(i in 1:nrow(sim_data$traindata)){
    train_pred[i] = as.numeric(mixnorm(x=sim_data$traindata[i,], centers0, centers1, s) > decision_thresh)
  }
  for(i in 1:nrow(sim_data$testdata)){
    test_pred[i] = as.numeric(mixnorm(x=sim_data$testdata[i,], centers0, centers1, s) > decision_thresh)
  }
  list(
    train_error = sum(sim_data$Ytrain  != train_pred) / length(sim_data$Ytrain),
    test_error = sum(sim_data$Ytest  != test_pred) / 
      length(sim_data$Ytest)
  )
}
```




### Simulating and Classifying
```{r}
numRuns = 50

lr_results = matrix(nrow=numRuns, ncol = 2)
qr_results = matrix(nrow=numRuns, ncol = 2)
Kstats = matrix(nrow=numRuns, ncol = 2)
knn_results = matrix(nrow=numRuns, ncol = 2)
bayes_results = matrix(nrow=numRuns, ncol = 2)


for(i in 1:numRuns){
  simdata = datagen(sim_params)
  
  lr_results[i,] = cbind(unlist(fit_lr_model(simdata)))
  qr_results[i,] = cbind(unlist(fit_qr_model(simdata)))
  Kstats[i,] = cbind(unlist(cvKNN(simdata$traindata, simdata$Ytrain)))
  knn_results[i,] = cbind(unlist(fit_knn_model(simdata, Kstats[i,1])))
  bayes_results[i,] = cbind(unlist(fit_bayes_model(simdata,sim_params$m0, sim_params$m1, sim_params$s)))
}
```


### Simulation Error Results
```{r}
boxplot(
  lr_results[,1], lr_results[,2], qr_results[,1], qr_results[,2], knn_results[,1], knn_results[,2], bayes_results[,1], bayes_results[,2],
  main = "Train and Test Error for Several Classification Methods",
  ylab = "Error",
  names = c("lr_train", "lr_test", "qr_train", "qr_test", "knn_train", "knn_test", "bayes_train", "bayes_test"),
  las = 2,
  col = c("orange", "dodgerblue")
  
)
```

### K value analysis
Mean
```{r}
mean(Kstats[,1])
```

Standard Error (Standard Deviation per #111)
```{r}
sqrt(sum((Kstats[,1] - mean(Kstats[,1])) ^ 2) / (nrow(Kstats) - 1))
```

